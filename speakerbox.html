<!doctype html>
<html class="no-js" lang="en">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />
<link rel="index" title="Index" href="genindex.html" /><link rel="search" title="Search" href="search.html" /><link rel="next" title="Contributing" href="contributing.html" /><link rel="prev" title="speakerbox" href="modules.html" />

    <!-- Generated with Sphinx 6.1.3 and Furo 2022.12.07 -->
        <title>speakerbox package - speakerbox 0.1.dev1+g0771d72 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/styles/furo.css?digest=91d0f0d1c444bdcb17a68e833c7a53903343c195" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/styles/furo-extensions.css?digest=30d1aed668e5c3a91c3e3bf6a60b675221979f0e" />
    
    


<style>
  body {
    --color-code-background: #eeffcc;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="index.html"><div class="brand">speakerbox 0.1.dev1+g0771d72 documentation</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="index.html">
  
  
  <span class="sidebar-brand-text">speakerbox 0.1.dev1+g0771d72 documentation</span>
  
</a><form class="sidebar-search-container" method="get" action="search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="index.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1 current has-children"><a class="reference internal" href="modules.html">Package modules</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l2 current current-page"><a class="current reference internal" href="#">speakerbox package</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="contributing.html">Contributing</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          
<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main">
          <section id="speakerbox-package">
<h1>speakerbox package<a class="headerlink" href="#speakerbox-package" title="Permalink to this heading">#</a></h1>
<section id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this heading">#</a></h2>
</section>
<section id="module-speakerbox.examples">
<span id="speakerbox-examples-module"></span><h2>speakerbox.examples module<a class="headerlink" href="#module-speakerbox.examples" title="Permalink to this heading">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="speakerbox.examples.IteratedModelEvalScores">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">speakerbox.examples.</span></span><span class="sig-name descname"><span class="pre">IteratedModelEvalScores</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">equalized_data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mean_audio_per_person_train</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">std_audio_per_person_train</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mean_audio_per_person_test</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">std_audio_per_person_test</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mean_audio_per_person_valid</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">std_audio_per_person_valid</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mean_accuracy</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">std_accuracy</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mean_precision</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">std_precision</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mean_recall</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">std_recall</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mean_duration</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">std_duration</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/speakerbox/examples.html#IteratedModelEvalScores"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#speakerbox.examples.IteratedModelEvalScores" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">DataClassJsonMixin</span></code></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="speakerbox.examples.IteratedModelEvalScores.dataset_size">
<span class="sig-name descname"><span class="pre">dataset_size</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><a class="headerlink" href="#speakerbox.examples.IteratedModelEvalScores.dataset_size" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="speakerbox.examples.IteratedModelEvalScores.equalized_data">
<span class="sig-name descname"><span class="pre">equalized_data</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#speakerbox.examples.IteratedModelEvalScores.equalized_data" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="speakerbox.examples.IteratedModelEvalScores.mean_accuracy">
<span class="sig-name descname"><span class="pre">mean_accuracy</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><a class="headerlink" href="#speakerbox.examples.IteratedModelEvalScores.mean_accuracy" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="speakerbox.examples.IteratedModelEvalScores.mean_audio_per_person_test">
<span class="sig-name descname"><span class="pre">mean_audio_per_person_test</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><a class="headerlink" href="#speakerbox.examples.IteratedModelEvalScores.mean_audio_per_person_test" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="speakerbox.examples.IteratedModelEvalScores.mean_audio_per_person_train">
<span class="sig-name descname"><span class="pre">mean_audio_per_person_train</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><a class="headerlink" href="#speakerbox.examples.IteratedModelEvalScores.mean_audio_per_person_train" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="speakerbox.examples.IteratedModelEvalScores.mean_audio_per_person_valid">
<span class="sig-name descname"><span class="pre">mean_audio_per_person_valid</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><a class="headerlink" href="#speakerbox.examples.IteratedModelEvalScores.mean_audio_per_person_valid" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="speakerbox.examples.IteratedModelEvalScores.mean_duration">
<span class="sig-name descname"><span class="pre">mean_duration</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><a class="headerlink" href="#speakerbox.examples.IteratedModelEvalScores.mean_duration" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="speakerbox.examples.IteratedModelEvalScores.mean_precision">
<span class="sig-name descname"><span class="pre">mean_precision</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><a class="headerlink" href="#speakerbox.examples.IteratedModelEvalScores.mean_precision" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="speakerbox.examples.IteratedModelEvalScores.mean_recall">
<span class="sig-name descname"><span class="pre">mean_recall</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><a class="headerlink" href="#speakerbox.examples.IteratedModelEvalScores.mean_recall" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="speakerbox.examples.IteratedModelEvalScores.std_accuracy">
<span class="sig-name descname"><span class="pre">std_accuracy</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><a class="headerlink" href="#speakerbox.examples.IteratedModelEvalScores.std_accuracy" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="speakerbox.examples.IteratedModelEvalScores.std_audio_per_person_test">
<span class="sig-name descname"><span class="pre">std_audio_per_person_test</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><a class="headerlink" href="#speakerbox.examples.IteratedModelEvalScores.std_audio_per_person_test" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="speakerbox.examples.IteratedModelEvalScores.std_audio_per_person_train">
<span class="sig-name descname"><span class="pre">std_audio_per_person_train</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><a class="headerlink" href="#speakerbox.examples.IteratedModelEvalScores.std_audio_per_person_train" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="speakerbox.examples.IteratedModelEvalScores.std_audio_per_person_valid">
<span class="sig-name descname"><span class="pre">std_audio_per_person_valid</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><a class="headerlink" href="#speakerbox.examples.IteratedModelEvalScores.std_audio_per_person_valid" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="speakerbox.examples.IteratedModelEvalScores.std_duration">
<span class="sig-name descname"><span class="pre">std_duration</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><a class="headerlink" href="#speakerbox.examples.IteratedModelEvalScores.std_duration" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="speakerbox.examples.IteratedModelEvalScores.std_precision">
<span class="sig-name descname"><span class="pre">std_precision</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><a class="headerlink" href="#speakerbox.examples.IteratedModelEvalScores.std_precision" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="speakerbox.examples.IteratedModelEvalScores.std_recall">
<span class="sig-name descname"><span class="pre">std_recall</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><a class="headerlink" href="#speakerbox.examples.IteratedModelEvalScores.std_recall" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="speakerbox.examples.ModelEvalScores">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">speakerbox.examples.</span></span><span class="sig-name descname"><span class="pre">ModelEvalScores</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">accuracy</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">precision</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">recall</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">duration</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/speakerbox/examples.html#ModelEvalScores"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#speakerbox.examples.ModelEvalScores" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">DataClassJsonMixin</span></code></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="speakerbox.examples.ModelEvalScores.accuracy">
<span class="sig-name descname"><span class="pre">accuracy</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><a class="headerlink" href="#speakerbox.examples.ModelEvalScores.accuracy" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="speakerbox.examples.ModelEvalScores.duration">
<span class="sig-name descname"><span class="pre">duration</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><a class="headerlink" href="#speakerbox.examples.ModelEvalScores.duration" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="speakerbox.examples.ModelEvalScores.precision">
<span class="sig-name descname"><span class="pre">precision</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><a class="headerlink" href="#speakerbox.examples.ModelEvalScores.precision" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="speakerbox.examples.ModelEvalScores.recall">
<span class="sig-name descname"><span class="pre">recall</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><a class="headerlink" href="#speakerbox.examples.ModelEvalScores.recall" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="speakerbox.examples.download_preprocessed_example_data">
<span class="sig-prename descclassname"><span class="pre">speakerbox.examples.</span></span><span class="sig-name descname"><span class="pre">download_preprocessed_example_data</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Path</span></span></span><a class="reference internal" href="_modules/speakerbox/examples.html#download_preprocessed_example_data"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#speakerbox.examples.download_preprocessed_example_data" title="Permalink to this definition">#</a></dt>
<dd><p>Install the example preprocessed dataset from Google Drive.</p>
<p>Stored to the: “example-speakerbox-dataset” directory.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt>Path</dt><dd><p>The path to the directory with all of the unzipped data.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="speakerbox.examples.train_and_eval_all_example_models">
<span class="sig-prename descclassname"><span class="pre">speakerbox.examples.</span></span><span class="sig-name descname"><span class="pre">train_and_eval_all_example_models</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">example_dataset_dir</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_iterations</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">182318512</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">equalize_data_within_splits</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">DataFrame</span></span></span><a class="reference internal" href="_modules/speakerbox/examples.html#train_and_eval_all_example_models"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#speakerbox.examples.train_and_eval_all_example_models" title="Permalink to this definition">#</a></dt>
<dd><p>Train and evaluate a model multiple times for each of the dataset sizes.</p>
<p>This was used to investigate the diminishing return of adding more data
to the model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>example_dataset_dir: Union[str, Path]</strong></dt><dd><p>Path to the downloaded and unzipped example dataset.</p>
</dd>
<dt><strong>n_iterations: int</strong></dt><dd><p>The number of train and evaluation iterations to try for this model
before averaging them all.
Default: 5</p>
</dd>
<dt><strong>seed: int</strong></dt><dd><p>A random seed to set global random state.</p>
</dd>
<dt><strong>equalize_data_within_splits: bool</strong></dt><dd><p>Should the data splits be equalized to the smallest number of examples
for any speaker in that split.
Default: False (allow different amounts of examples per label)</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>pd.DataFrame</dt><dd><p>A DataFrame of results for all the models tested.</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#speakerbox.examples.train_and_eval_example_model" title="speakerbox.examples.train_and_eval_example_model"><code class="xref py py-obj docutils literal notranslate"><span class="pre">train_and_eval_example_model</span></code></a></dt><dd><p>The function used to train and eval a single model dataset size.</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="speakerbox.examples.train_and_eval_example_model">
<span class="sig-prename descclassname"><span class="pre">speakerbox.examples.</span></span><span class="sig-name descname"><span class="pre">train_and_eval_example_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">example_dataset_dir</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataset_size_str</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'15-minutes'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'30-minutes'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'60-minutes'</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_iterations</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">182318512</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">equalize_data_within_splits</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#speakerbox.examples.IteratedModelEvalScores" title="speakerbox.examples.IteratedModelEvalScores"><span class="pre">IteratedModelEvalScores</span></a></span></span><a class="reference internal" href="_modules/speakerbox/examples.html#train_and_eval_example_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#speakerbox.examples.train_and_eval_example_model" title="Permalink to this definition">#</a></dt>
<dd><p>Train and evaluate a model multiple times for one of the dataset sizes.</p>
<p>This was used to investigate the diminishing return of adding more data
to the model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>example_dataset_dir: Union[str, Path]</strong></dt><dd><p>Path to the downloaded and unzipped example dataset.</p>
</dd>
<dt><strong>dataset_size_str: Literal[“15-minutes”, “30-minutes”, “60-minutes”]</strong></dt><dd><p>The dataset size to choose from. This will load (and potentially)
subset the packaged data.</p>
</dd>
<dt><strong>n_iterations: int</strong></dt><dd><p>The number of train and evaluation iterations to try for this model
before averaging them all.
Default: 5</p>
</dd>
<dt><strong>seed: int</strong></dt><dd><p>A random seed to set global random state.</p>
</dd>
<dt><strong>equalize_data_within_splits: bool</strong></dt><dd><p>Should the data splits be equalized to the smallest number of examples
for any speaker in that split.
Default: False (allow different amounts of examples per label)</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>IteratedModelEvalScores</dt><dd><p>The average accuracy, precision, recall, and duration over the
training and evaluation iterations.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-speakerbox.main">
<span id="speakerbox-main-module"></span><h2>speakerbox.main module<a class="headerlink" href="#module-speakerbox.main" title="Permalink to this heading">#</a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="speakerbox.main.apply">
<span class="sig-prename descclassname"><span class="pre">speakerbox.main.</span></span><span class="sig-name descname"><span class="pre">apply</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">audio</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'diarize'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'naive'</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'diarize'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_chunk_duration</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_chunk_duration</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">2.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">confidence_threshold</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.85</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Annotation</span></span></span><a class="reference internal" href="_modules/speakerbox/main.html#apply"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#speakerbox.main.apply" title="Permalink to this definition">#</a></dt>
<dd><p>Iteritively apply the model across chunks of an audio file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>audio: Union[str, Path]</strong></dt><dd><p>The audio filepath.</p>
</dd>
<dt><strong>model: str</strong></dt><dd><p>The path to the trained audio-classification model.</p>
</dd>
<dt><strong>mode: Literal[“diarize”, “naive”]</strong></dt><dd><p>Which mode to use for processing. “diarize” will diarize the audio
prior to generating chunks to classify. “naive” will iteratively process
chunks. “naive” is assumed to be faster but have worse performance.
Default: “diarize”</p>
</dd>
<dt><strong>min_chunk_duration: float</strong></dt><dd><p>The minimum size in seconds a chunk of audio is allowed to be
for it to be ran through the classification pipeline.
Default: 0.5 seconds</p>
</dd>
<dt><strong>max_chunk_duration: float</strong></dt><dd><p>The maximum size in seconds a chunk of audio is allowed to be
for it to be ran through the classification pipeline.
Default: 2 seconds</p>
</dd>
<dt><strong>confidence_threshold: float</strong></dt><dd><p>A value to act as a lower bound to the reported confidence
of the model prediction. Any classification that has a confidence
lower than this value will be ignore and not added as a segment.
Default: 0.95 (fairly strict / must have high confidence in prediction)</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>Annotation</dt><dd><p>A pyannote.core Annotation with all labeled segments.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="speakerbox.main.eval_model">
<span class="sig-prename descclassname"><span class="pre">speakerbox.main.</span></span><span class="sig-name descname"><span class="pre">eval_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">validation_dataset</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dataset</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'trained-speakerbox'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/speakerbox/main.html#eval_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#speakerbox.main.eval_model" title="Permalink to this definition">#</a></dt>
<dd><p>Evaluate a trained model.</p>
<p>This will store two files in the model directory, one for the accuracy, precision,
and recall in a markdown file and the other is the generated top one confusion
matrix as a PNG file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>validation_dataset: Dataset</strong></dt><dd><p>The dataset to validate the model against.</p>
</dd>
<dt><strong>model_name: str</strong></dt><dd><p>A name for the model. This will also create a directory with the same name
to store the produced model in.
Default: “trained-speakerbox”</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>accuracy: float</dt><dd><p>The model accuracy as returned by sklearn.metrics.accuracy_score.</p>
</dd>
<dt>precision: float</dt><dd><p>The model (weighted) precision as returned by sklearn.metrics.precision_score.</p>
</dd>
<dt>recall: float</dt><dd><p>The model (weighted) recall as returned by sklearn.metrics.recall_score.</p>
</dd>
<dt>loss: float</dt><dd><p>The model log loss as returned by sklearn.metrics.log_loss.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="speakerbox.main.train">
<span class="sig-prename descclassname"><span class="pre">speakerbox.main.</span></span><span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DatasetDict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'trained-speakerbox'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_base</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'superb/wav2vec2-base-superb-sid'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_duration</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">2.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_cpu</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trainer_arguments_kws</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">{'eval_accumulation_steps':</span> <span class="pre">40,</span> <span class="pre">'evaluation_strategy':</span> <span class="pre">'epoch',</span> <span class="pre">'gradient_accumulation_steps':</span> <span class="pre">1,</span> <span class="pre">'gradient_checkpointing':</span> <span class="pre">True,</span> <span class="pre">'learning_rate':</span> <span class="pre">3e-05,</span> <span class="pre">'load_best_model_at_end':</span> <span class="pre">True,</span> <span class="pre">'logging_steps':</span> <span class="pre">10,</span> <span class="pre">'metric_for_best_model':</span> <span class="pre">'accuracy',</span> <span class="pre">'num_train_epochs':</span> <span class="pre">5,</span> <span class="pre">'per_device_eval_batch_size':</span> <span class="pre">8,</span> <span class="pre">'per_device_train_batch_size':</span> <span class="pre">8,</span> <span class="pre">'save_strategy':</span> <span class="pre">'epoch',</span> <span class="pre">'warmup_ratio':</span> <span class="pre">0.1}</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Path</span></span></span><a class="reference internal" href="_modules/speakerbox/main.html#train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#speakerbox.main.train" title="Permalink to this definition">#</a></dt>
<dd><p>Train a speaker classification model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>dataset: DatasetDict</strong></dt><dd><p>The datasets to use for training, testing, and validation.
Should only contain the columns/features: “label” and “audio”.
The values in the “audio” column should be paths to the audio files.</p>
</dd>
<dt><strong>model_name: str</strong></dt><dd><p>A name for the model. This will also create a directory with the
same name to store the produced model in.
Default: “trained-speakerbox”</p>
</dd>
<dt><strong>model_base: str</strong></dt><dd><p>The model base to use before fine tuning.</p>
</dd>
<dt><strong>max_duration: float</strong></dt><dd><p>The maximum duration to use for each audio clip.
Any clips longer than this will be trimmed.
Default: 2.0</p>
</dd>
<dt><strong>seed: Optional[int]</strong></dt><dd><p>Seed to pass to torch, numpy, and Python RNGs.
Default: None (do not set a seed)</p>
</dd>
<dt><strong>use_cpu: bool</strong></dt><dd><p>Should the model be trained using CPU.
This also sets <cite>no_cuda=True</cite> on TrainerArguments.
Default: False (use GPU if available)</p>
</dd>
<dt><strong>trainer_arguments_kws: Dict[Any]</strong></dt><dd><p>Any additional keyword arguments to be passed to the HuggingFace
TrainerArguments object.
Default: DEFAULT_TRAINER_ARGUMENTS_ARGS</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>model_storage_path: Path</dt><dd><p>The path to the directory where the model is stored.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-speakerbox.preprocess">
<span id="speakerbox-preprocess-module"></span><h2>speakerbox.preprocess module<a class="headerlink" href="#module-speakerbox.preprocess" title="Permalink to this heading">#</a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="speakerbox.preprocess.diarize_and_split_audio">
<span class="sig-prename descclassname"><span class="pre">speakerbox.preprocess.</span></span><span class="sig-name descname"><span class="pre">diarize_and_split_audio</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">audio_file</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">storage_dir</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Path</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_audio_chunk_duration</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">diarization_pipeline</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Pipeline</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hf_token</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Path</span></span></span><a class="reference internal" href="_modules/speakerbox/preprocess.html#diarize_and_split_audio"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#speakerbox.preprocess.diarize_and_split_audio" title="Permalink to this definition">#</a></dt>
<dd><p>Diarize a single audio file and split the file into smaller chunks stored into
directories with the unlabeled speaker annotation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>audio_file: Union[str, Path]</strong></dt><dd><p>The audio file to diarize and split.</p>
</dd>
<dt><strong>storage_dir: Optional[Union[str, Path]]</strong></dt><dd><p>A specific directory to store the produced chunks to.
Default: None (use the audio file name to create a new directory)</p>
</dd>
<dt><strong>min_audio_chunk_duration: float</strong></dt><dd><p>Length of the minimum audio duration to allow through after chunking.
default: 0.5 seconds</p>
</dd>
<dt><strong>diarization_pipeline: Optional[Pipeline]</strong></dt><dd><p>A preloaded PyAnnote Pipeline.
Default: None (load default)</p>
</dd>
<dt><strong>seed: Optional[int]</strong></dt><dd><p>Seed to pass to torch, numpy, and Python RNGs.
Default: None (do not set a seed)</p>
</dd>
<dt><strong>hf_token: Optional[str]</strong></dt><dd><p>Huggingface user access token to download the diarization model.
Can also be set with the HUGGINGFACE_TOKEN environment variable.
<a class="reference external" href="https://hf.co/settings/tokens">https://hf.co/settings/tokens</a></p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>storage_dir: Path</dt><dd><p>The path to where all the chunked audio was stored.</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#speakerbox.preprocess.expand_labeled_diarized_audio_dir_to_dataset" title="speakerbox.preprocess.expand_labeled_diarized_audio_dir_to_dataset"><code class="xref py py-obj docutils literal notranslate"><span class="pre">expand_labeled_diarized_audio_dir_to_dataset</span></code></a></dt><dd><p>After labeling the audio in the produced diarized audio directory, expand the labeled data into a dataset ready for training.</p>
</dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>Prior to using this function you need to accept user conditions:
<a class="reference external" href="https://hf.co/pyannote/speaker-diarization">https://hf.co/pyannote/speaker-diarization</a> and <a class="reference external" href="https://hf.co/pyannote/segmentation">https://hf.co/pyannote/segmentation</a></p>
<p>The output directory structure of the produced chunks will follow the pattern:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>{storage_dir}/
├── SPEAKER_00
│   ├── {start_time_millis}-{start_end_millis}.wav
│   └── {start_time_millis}-{start_end_millis}.wav
├── SPEAKER_01
│   ├── {start_time_millis}-{start_end_millis}.wav
│   └── {start_time_millis}-{start_end_millis}.wav
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="speakerbox.preprocess.expand_gecko_annotations_to_dataset">
<span class="sig-prename descclassname"><span class="pre">speakerbox.preprocess.</span></span><span class="sig-name descname"><span class="pre">expand_gecko_annotations_to_dataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">annotations_and_audios</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#speakerbox.types.GeckoAnnotationAndAudio" title="speakerbox.types.GeckoAnnotationAndAudio"><span class="pre">GeckoAnnotationAndAudio</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">audio_output_dir</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Path</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'chunked-audio/'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">overwrite</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_audio_chunk_duration</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_audio_chunk_duration</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">2.0</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">DataFrame</span></span></span><a class="reference internal" href="_modules/speakerbox/preprocess.html#expand_gecko_annotations_to_dataset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#speakerbox.preprocess.expand_gecko_annotations_to_dataset" title="Permalink to this definition">#</a></dt>
<dd><p>Expand a list of annotation and audio files into a full dataset to be used for
training and testing a speaker classification model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>annotations_and_audios: List[GeckoAnnotationAndAudio]</strong></dt><dd><p>A list of annotation and their matching audio files to expand into a speaker,
audio file path, start and end times.</p>
</dd>
<dt><strong>audio_output_dir: Union[str, Path]</strong></dt><dd><p>A directory path to store the chunked audio files in.
Default: “chunked-audio” directory in the current working directory.</p>
</dd>
<dt><strong>overwrite: bool</strong></dt><dd><p>When writting out an audio chunk, should existing files be overwritten.
Default: False (do not overwrite)</p>
</dd>
<dt><strong>min_audio_chunk_duration: float</strong></dt><dd><p>Length of the minimum audio duration to allow through after chunking.
default: 0.5 seconds</p>
</dd>
<dt><strong>max_audio_chunk_duration: float</strong></dt><dd><p>Length of the maximum audio duration to split larger audio files into.
Default: 2.0 seconds</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>dataset: pd.DataFrame</dt><dd><p>The expanded dataset with columns: conversation_id, label, audio, duration</p>
</dd>
</dl>
</dd>
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt>NotADirectoryError</dt><dd><p>A file exists at the specified destination.</p>
</dd>
<dt>FileExistsError</dt><dd><p>A file exists at the target chunk audio location but overwrite is False.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>Generated and attached conversation ids are pulled from the annotation file name.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="speakerbox.preprocess.expand_labeled_diarized_audio_dir_to_dataset">
<span class="sig-prename descclassname"><span class="pre">speakerbox.preprocess.</span></span><span class="sig-name descname"><span class="pre">expand_labeled_diarized_audio_dir_to_dataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">labeled_diarized_audio_dir</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Path</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Path</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Path</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">audio_output_dir</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Path</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'chunked-audio/'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">overwrite</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_audio_chunk_duration</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_audio_chunk_duration</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">2.0</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">DataFrame</span></span></span><a class="reference internal" href="_modules/speakerbox/preprocess.html#expand_labeled_diarized_audio_dir_to_dataset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#speakerbox.preprocess.expand_labeled_diarized_audio_dir_to_dataset" title="Permalink to this definition">#</a></dt>
<dd><p>Expand the provided labeled diarized audio into a dataset ready for training.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>labeled_diarized_audio_dir: Union[Union[str, Path], List[Union[str, Path]]]</strong></dt><dd><p>A path or list of paths to diarization results directories. These directories
should no longer have the “SPEAKER_00”, “SPEAKER_01”, default labeling but
expert annotated labels.</p>
</dd>
<dt><strong>audio_output_dir: Union[str, Path]</strong></dt><dd><p>A directory path to store the chunked audio files in.
Default: “chunked-audio” directory in the current working directory.</p>
</dd>
<dt><strong>overwrite: bool</strong></dt><dd><p>When writting out an audio chunk, should existing files be overwritten.
Default: False (do not overwrite)</p>
</dd>
<dt><strong>min_audio_chunk_duration: float</strong></dt><dd><p>Length of the minimum audio duration to allow through after chunking.
default: 0.5 seconds</p>
</dd>
<dt><strong>max_audio_chunk_duration: float</strong></dt><dd><p>Length of the maximum audio duration to split larger audio files into.
Default: 2.0 seconds</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>dataset: pd.DataFrame</dt><dd><p>The expanded dataset with columns: conversation_id, label, audio, duration</p>
</dd>
</dl>
</dd>
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt>NotADirectoryError</dt><dd><p>A file exists at the specified destination.</p>
</dd>
<dt>FileExistsError</dt><dd><p>A file exists at the target chunk audio location but overwrite is False.</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#speakerbox.preprocess.diarize_and_split_audio" title="speakerbox.preprocess.diarize_and_split_audio"><code class="xref py py-obj docutils literal notranslate"><span class="pre">diarize_and_split_audio</span></code></a></dt><dd><p>Function to diarize an audio file and split into annotation directories.</p>
</dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>The provided labeled diarized audio directory(s) should have the
following structure:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>{labeled_diarized_audio_dir}/
├── label
│   ├── 1.wav
│   └── 2.wav
├── second_label
│   ├── 1.wav
│   └── 2.wav
</pre></div>
</div>
<p>Generated and attached conversation ids are pulled from the labeled diarized audio
directory names.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="speakerbox.preprocess.prepare_dataset">
<span class="sig-prename descclassname"><span class="pre">speakerbox.preprocess.</span></span><span class="sig-name descname"><span class="pre">prepare_dataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_and_valid_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">equalize_data_within_splits</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_iterations</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">DatasetDict</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">DataFrame</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/speakerbox/preprocess.html#prepare_dataset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#speakerbox.preprocess.prepare_dataset" title="Permalink to this definition">#</a></dt>
<dd><p>Prepare a dataset for training a new speakerbox / audio-classification model.</p>
<p>This function attempts to randomly create train, test, and validation splits
from the provided dataframe that meet the following two conditions:</p>
<p>1. There is data holdout by conversation_id. I.e. if the dataset contains data from
nine unique conversation ids, the training, test, and validation sets should all
have different conversation ids (train has 0, 1, 2, 3; test has 4, 5, 6; validation
has 7, 8).</p>
<p>2. There is data stratification by label. I.e. if the dataset contains nine unique
labels, the training, test, and validation sets should each have all nine labels
present (train, test, and validation all have labels 0-8).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>dataset: pd.DataFrame</strong></dt><dd><p>An expanded dataset with columns: conversation_id, label, audio, duration</p>
</dd>
<dt><strong>test_and_valid_size: float</strong></dt><dd><p>How much of the dataset to use for the combined test and validation sets
as a percent (i.e. 0.4 = 40% of the dataset).
The test and validation sets will further split this in half (i.e. 0.4 = 40%
which means 20% of the total data for testing and 20% of the total data for
validation).</p>
</dd>
<dt><strong>equalize_data_within_splits: bool</strong></dt><dd><p>After finding valid train, test, and validation splits, should the data within
each split be reduced to have an equal number of data for each label.
Default: False (Do not equalize labels within splits)</p>
</dd>
<dt><strong>n_iterations: int</strong></dt><dd><p>The number of iterations to attempt to find viable train, test, and validation
sets.
Default: 100</p>
</dd>
<dt><strong>seed: Optional[int]</strong></dt><dd><p>Seed to pass to torch, numpy, and Python RNGs.
Default: None (do not set a seed)</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>dataset: DatasetDict</dt><dd><p>The prepared dataset split into train, test, and validation splits.</p>
</dd>
<dt>value_counts: pd.DataFrame</dt><dd><p>A value count table where each row is a different label and each column is the
count of that label in the matching train, test, or validation set.</p>
</dd>
</dl>
</dd>
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt>ValueError</dt><dd><p>Could not find train, test, and validation sets that meet the holdout and
stratification criteria after n iterations. Recommended to annotate more data.</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#speakerbox.preprocess.expand_labeled_diarized_audio_dir_to_dataset" title="speakerbox.preprocess.expand_labeled_diarized_audio_dir_to_dataset"><code class="xref py py-obj docutils literal notranslate"><span class="pre">expand_labeled_diarized_audio_dir_to_dataset</span></code></a></dt><dd><p>Function to move from a directory of diarized audio (or multiple) into a dataset to provide to this function.</p>
</dd>
<dt><a class="reference internal" href="#speakerbox.preprocess.expand_gecko_annotations_to_dataset" title="speakerbox.preprocess.expand_gecko_annotations_to_dataset"><code class="xref py py-obj docutils literal notranslate"><span class="pre">expand_gecko_annotations_to_dataset</span></code></a></dt><dd><p>Function to move from a gecko annotation file (or multiple) into a dataset to provide to this function.</p>
</dd>
</dl>
</div>
</dd></dl>

</section>
<section id="module-speakerbox.types">
<span id="speakerbox-types-module"></span><h2>speakerbox.types module<a class="headerlink" href="#module-speakerbox.types" title="Permalink to this heading">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="speakerbox.types.AnnotatedAudio">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">speakerbox.types.</span></span><span class="sig-name descname"><span class="pre">AnnotatedAudio</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">conversation_id</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">audio</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">duration</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/speakerbox/types.html#AnnotatedAudio"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#speakerbox.types.AnnotatedAudio" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="speakerbox.types.AnnotatedAudio.audio">
<span class="sig-name descname"><span class="pre">audio</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><a class="headerlink" href="#speakerbox.types.AnnotatedAudio.audio" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="speakerbox.types.AnnotatedAudio.conversation_id">
<span class="sig-name descname"><span class="pre">conversation_id</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><a class="headerlink" href="#speakerbox.types.AnnotatedAudio.conversation_id" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="speakerbox.types.AnnotatedAudio.duration">
<span class="sig-name descname"><span class="pre">duration</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><a class="headerlink" href="#speakerbox.types.AnnotatedAudio.duration" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="speakerbox.types.AnnotatedAudio.from_dict">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">kvs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">list</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">float</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">bool</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">infer_missing</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">A</span></span></span><a class="headerlink" href="#speakerbox.types.AnnotatedAudio.from_dict" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="speakerbox.types.AnnotatedAudio.from_json">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_json</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">s</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">bytes</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">bytearray</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parse_float</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parse_int</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parse_constant</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">infer_missing</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kw</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">A</span></span></span><a class="headerlink" href="#speakerbox.types.AnnotatedAudio.from_json" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="speakerbox.types.AnnotatedAudio.label">
<span class="sig-name descname"><span class="pre">label</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><a class="headerlink" href="#speakerbox.types.AnnotatedAudio.label" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="speakerbox.types.AnnotatedAudio.schema">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">schema</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">infer_missing</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">only</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">many</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">load_only</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dump_only</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">partial</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">unknown</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">SchemaF</span><span class="p"><span class="pre">[</span></span><span class="pre">A</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#speakerbox.types.AnnotatedAudio.schema" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="speakerbox.types.AnnotatedAudio.to_dict">
<span class="sig-name descname"><span class="pre">to_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">encode_json</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">dict</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">list</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">float</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">bool</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#speakerbox.types.AnnotatedAudio.to_dict" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="speakerbox.types.AnnotatedAudio.to_json">
<span class="sig-name descname"><span class="pre">to_json</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skipkeys</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ensure_ascii</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">check_circular</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">allow_nan</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">indent</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">separators</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">default</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sort_keys</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kw</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">str</span></span></span><a class="headerlink" href="#speakerbox.types.AnnotatedAudio.to_json" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="speakerbox.types.GeckoAnnotationAndAudio">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">speakerbox.types.</span></span><span class="sig-name descname"><span class="pre">GeckoAnnotationAndAudio</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">annotation_file</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">audio_file</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/speakerbox/types.html#GeckoAnnotationAndAudio"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#speakerbox.types.GeckoAnnotationAndAudio" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">NamedTuple</span></code></p>
<p>Create new instance of GeckoAnnotationAndAudio(annotation_file, audio_file)</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="speakerbox.types.GeckoAnnotationAndAudio.annotation_file">
<span class="sig-name descname"><span class="pre">annotation_file</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Path</span></em><a class="headerlink" href="#speakerbox.types.GeckoAnnotationAndAudio.annotation_file" title="Permalink to this definition">#</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="speakerbox.types.GeckoAnnotationAndAudio.audio_file">
<span class="sig-name descname"><span class="pre">audio_file</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Path</span></em><a class="headerlink" href="#speakerbox.types.GeckoAnnotationAndAudio.audio_file" title="Permalink to this definition">#</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

</dd></dl>

</section>
<section id="module-speakerbox.utils">
<span id="speakerbox-utils-module"></span><h2>speakerbox.utils module<a class="headerlink" href="#module-speakerbox.utils" title="Permalink to this heading">#</a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="speakerbox.utils.set_global_seed">
<span class="sig-prename descclassname"><span class="pre">speakerbox.utils.</span></span><span class="sig-name descname"><span class="pre">set_global_seed</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="_modules/speakerbox/utils.html#set_global_seed"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#speakerbox.utils.set_global_seed" title="Permalink to this definition">#</a></dt>
<dd><p>Set the global RNG seed for torch, numpy, and Python.</p>
</dd></dl>

</section>
<section id="module-speakerbox">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-speakerbox" title="Permalink to this heading">#</a></h2>
<p>Top-level package for speakerbox.</p>
<dl class="py function">
<dt class="sig sig-object py" id="speakerbox.apply">
<span class="sig-prename descclassname"><span class="pre">speakerbox.</span></span><span class="sig-name descname"><span class="pre">apply</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">audio</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'diarize'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'naive'</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'diarize'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_chunk_duration</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_chunk_duration</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">2.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">confidence_threshold</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.85</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Annotation</span></span></span><a class="reference internal" href="_modules/speakerbox/main.html#apply"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#speakerbox.apply" title="Permalink to this definition">#</a></dt>
<dd><p>Iteritively apply the model across chunks of an audio file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>audio: Union[str, Path]</strong></dt><dd><p>The audio filepath.</p>
</dd>
<dt><strong>model: str</strong></dt><dd><p>The path to the trained audio-classification model.</p>
</dd>
<dt><strong>mode: Literal[“diarize”, “naive”]</strong></dt><dd><p>Which mode to use for processing. “diarize” will diarize the audio
prior to generating chunks to classify. “naive” will iteratively process
chunks. “naive” is assumed to be faster but have worse performance.
Default: “diarize”</p>
</dd>
<dt><strong>min_chunk_duration: float</strong></dt><dd><p>The minimum size in seconds a chunk of audio is allowed to be
for it to be ran through the classification pipeline.
Default: 0.5 seconds</p>
</dd>
<dt><strong>max_chunk_duration: float</strong></dt><dd><p>The maximum size in seconds a chunk of audio is allowed to be
for it to be ran through the classification pipeline.
Default: 2 seconds</p>
</dd>
<dt><strong>confidence_threshold: float</strong></dt><dd><p>A value to act as a lower bound to the reported confidence
of the model prediction. Any classification that has a confidence
lower than this value will be ignore and not added as a segment.
Default: 0.95 (fairly strict / must have high confidence in prediction)</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>Annotation</dt><dd><p>A pyannote.core Annotation with all labeled segments.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="speakerbox.eval_model">
<span class="sig-prename descclassname"><span class="pre">speakerbox.</span></span><span class="sig-name descname"><span class="pre">eval_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">validation_dataset</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dataset</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'trained-speakerbox'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/speakerbox/main.html#eval_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#speakerbox.eval_model" title="Permalink to this definition">#</a></dt>
<dd><p>Evaluate a trained model.</p>
<p>This will store two files in the model directory, one for the accuracy, precision,
and recall in a markdown file and the other is the generated top one confusion
matrix as a PNG file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>validation_dataset: Dataset</strong></dt><dd><p>The dataset to validate the model against.</p>
</dd>
<dt><strong>model_name: str</strong></dt><dd><p>A name for the model. This will also create a directory with the same name
to store the produced model in.
Default: “trained-speakerbox”</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>accuracy: float</dt><dd><p>The model accuracy as returned by sklearn.metrics.accuracy_score.</p>
</dd>
<dt>precision: float</dt><dd><p>The model (weighted) precision as returned by sklearn.metrics.precision_score.</p>
</dd>
<dt>recall: float</dt><dd><p>The model (weighted) recall as returned by sklearn.metrics.recall_score.</p>
</dd>
<dt>loss: float</dt><dd><p>The model log loss as returned by sklearn.metrics.log_loss.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="speakerbox.train">
<span class="sig-prename descclassname"><span class="pre">speakerbox.</span></span><span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DatasetDict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'trained-speakerbox'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_base</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'superb/wav2vec2-base-superb-sid'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_duration</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">2.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_cpu</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trainer_arguments_kws</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">{'eval_accumulation_steps':</span> <span class="pre">40,</span> <span class="pre">'evaluation_strategy':</span> <span class="pre">'epoch',</span> <span class="pre">'gradient_accumulation_steps':</span> <span class="pre">1,</span> <span class="pre">'gradient_checkpointing':</span> <span class="pre">True,</span> <span class="pre">'learning_rate':</span> <span class="pre">3e-05,</span> <span class="pre">'load_best_model_at_end':</span> <span class="pre">True,</span> <span class="pre">'logging_steps':</span> <span class="pre">10,</span> <span class="pre">'metric_for_best_model':</span> <span class="pre">'accuracy',</span> <span class="pre">'num_train_epochs':</span> <span class="pre">5,</span> <span class="pre">'per_device_eval_batch_size':</span> <span class="pre">8,</span> <span class="pre">'per_device_train_batch_size':</span> <span class="pre">8,</span> <span class="pre">'save_strategy':</span> <span class="pre">'epoch',</span> <span class="pre">'warmup_ratio':</span> <span class="pre">0.1}</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Path</span></span></span><a class="reference internal" href="_modules/speakerbox/main.html#train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#speakerbox.train" title="Permalink to this definition">#</a></dt>
<dd><p>Train a speaker classification model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>dataset: DatasetDict</strong></dt><dd><p>The datasets to use for training, testing, and validation.
Should only contain the columns/features: “label” and “audio”.
The values in the “audio” column should be paths to the audio files.</p>
</dd>
<dt><strong>model_name: str</strong></dt><dd><p>A name for the model. This will also create a directory with the
same name to store the produced model in.
Default: “trained-speakerbox”</p>
</dd>
<dt><strong>model_base: str</strong></dt><dd><p>The model base to use before fine tuning.</p>
</dd>
<dt><strong>max_duration: float</strong></dt><dd><p>The maximum duration to use for each audio clip.
Any clips longer than this will be trimmed.
Default: 2.0</p>
</dd>
<dt><strong>seed: Optional[int]</strong></dt><dd><p>Seed to pass to torch, numpy, and Python RNGs.
Default: None (do not set a seed)</p>
</dd>
<dt><strong>use_cpu: bool</strong></dt><dd><p>Should the model be trained using CPU.
This also sets <cite>no_cuda=True</cite> on TrainerArguments.
Default: False (use GPU if available)</p>
</dd>
<dt><strong>trainer_arguments_kws: Dict[Any]</strong></dt><dd><p>Any additional keyword arguments to be passed to the HuggingFace
TrainerArguments object.
Default: DEFAULT_TRAINER_ARGUMENTS_ARGS</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>model_storage_path: Path</dt><dd><p>The path to the directory where the model is stored.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="contributing.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">Contributing</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="modules.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">speakerbox</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2022
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">speakerbox package</a><ul>
<li><a class="reference internal" href="#submodules">Submodules</a></li>
<li><a class="reference internal" href="#module-speakerbox.examples">speakerbox.examples module</a><ul>
<li><a class="reference internal" href="#speakerbox.examples.IteratedModelEvalScores"><code class="docutils literal notranslate"><span class="pre">IteratedModelEvalScores</span></code></a><ul>
<li><a class="reference internal" href="#speakerbox.examples.IteratedModelEvalScores.dataset_size"><code class="docutils literal notranslate"><span class="pre">IteratedModelEvalScores.dataset_size</span></code></a></li>
<li><a class="reference internal" href="#speakerbox.examples.IteratedModelEvalScores.equalized_data"><code class="docutils literal notranslate"><span class="pre">IteratedModelEvalScores.equalized_data</span></code></a></li>
<li><a class="reference internal" href="#speakerbox.examples.IteratedModelEvalScores.mean_accuracy"><code class="docutils literal notranslate"><span class="pre">IteratedModelEvalScores.mean_accuracy</span></code></a></li>
<li><a class="reference internal" href="#speakerbox.examples.IteratedModelEvalScores.mean_audio_per_person_test"><code class="docutils literal notranslate"><span class="pre">IteratedModelEvalScores.mean_audio_per_person_test</span></code></a></li>
<li><a class="reference internal" href="#speakerbox.examples.IteratedModelEvalScores.mean_audio_per_person_train"><code class="docutils literal notranslate"><span class="pre">IteratedModelEvalScores.mean_audio_per_person_train</span></code></a></li>
<li><a class="reference internal" href="#speakerbox.examples.IteratedModelEvalScores.mean_audio_per_person_valid"><code class="docutils literal notranslate"><span class="pre">IteratedModelEvalScores.mean_audio_per_person_valid</span></code></a></li>
<li><a class="reference internal" href="#speakerbox.examples.IteratedModelEvalScores.mean_duration"><code class="docutils literal notranslate"><span class="pre">IteratedModelEvalScores.mean_duration</span></code></a></li>
<li><a class="reference internal" href="#speakerbox.examples.IteratedModelEvalScores.mean_precision"><code class="docutils literal notranslate"><span class="pre">IteratedModelEvalScores.mean_precision</span></code></a></li>
<li><a class="reference internal" href="#speakerbox.examples.IteratedModelEvalScores.mean_recall"><code class="docutils literal notranslate"><span class="pre">IteratedModelEvalScores.mean_recall</span></code></a></li>
<li><a class="reference internal" href="#speakerbox.examples.IteratedModelEvalScores.std_accuracy"><code class="docutils literal notranslate"><span class="pre">IteratedModelEvalScores.std_accuracy</span></code></a></li>
<li><a class="reference internal" href="#speakerbox.examples.IteratedModelEvalScores.std_audio_per_person_test"><code class="docutils literal notranslate"><span class="pre">IteratedModelEvalScores.std_audio_per_person_test</span></code></a></li>
<li><a class="reference internal" href="#speakerbox.examples.IteratedModelEvalScores.std_audio_per_person_train"><code class="docutils literal notranslate"><span class="pre">IteratedModelEvalScores.std_audio_per_person_train</span></code></a></li>
<li><a class="reference internal" href="#speakerbox.examples.IteratedModelEvalScores.std_audio_per_person_valid"><code class="docutils literal notranslate"><span class="pre">IteratedModelEvalScores.std_audio_per_person_valid</span></code></a></li>
<li><a class="reference internal" href="#speakerbox.examples.IteratedModelEvalScores.std_duration"><code class="docutils literal notranslate"><span class="pre">IteratedModelEvalScores.std_duration</span></code></a></li>
<li><a class="reference internal" href="#speakerbox.examples.IteratedModelEvalScores.std_precision"><code class="docutils literal notranslate"><span class="pre">IteratedModelEvalScores.std_precision</span></code></a></li>
<li><a class="reference internal" href="#speakerbox.examples.IteratedModelEvalScores.std_recall"><code class="docutils literal notranslate"><span class="pre">IteratedModelEvalScores.std_recall</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#speakerbox.examples.ModelEvalScores"><code class="docutils literal notranslate"><span class="pre">ModelEvalScores</span></code></a><ul>
<li><a class="reference internal" href="#speakerbox.examples.ModelEvalScores.accuracy"><code class="docutils literal notranslate"><span class="pre">ModelEvalScores.accuracy</span></code></a></li>
<li><a class="reference internal" href="#speakerbox.examples.ModelEvalScores.duration"><code class="docutils literal notranslate"><span class="pre">ModelEvalScores.duration</span></code></a></li>
<li><a class="reference internal" href="#speakerbox.examples.ModelEvalScores.precision"><code class="docutils literal notranslate"><span class="pre">ModelEvalScores.precision</span></code></a></li>
<li><a class="reference internal" href="#speakerbox.examples.ModelEvalScores.recall"><code class="docutils literal notranslate"><span class="pre">ModelEvalScores.recall</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#speakerbox.examples.download_preprocessed_example_data"><code class="docutils literal notranslate"><span class="pre">download_preprocessed_example_data()</span></code></a></li>
<li><a class="reference internal" href="#speakerbox.examples.train_and_eval_all_example_models"><code class="docutils literal notranslate"><span class="pre">train_and_eval_all_example_models()</span></code></a></li>
<li><a class="reference internal" href="#speakerbox.examples.train_and_eval_example_model"><code class="docutils literal notranslate"><span class="pre">train_and_eval_example_model()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#module-speakerbox.main">speakerbox.main module</a><ul>
<li><a class="reference internal" href="#speakerbox.main.apply"><code class="docutils literal notranslate"><span class="pre">apply()</span></code></a></li>
<li><a class="reference internal" href="#speakerbox.main.eval_model"><code class="docutils literal notranslate"><span class="pre">eval_model()</span></code></a></li>
<li><a class="reference internal" href="#speakerbox.main.train"><code class="docutils literal notranslate"><span class="pre">train()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#module-speakerbox.preprocess">speakerbox.preprocess module</a><ul>
<li><a class="reference internal" href="#speakerbox.preprocess.diarize_and_split_audio"><code class="docutils literal notranslate"><span class="pre">diarize_and_split_audio()</span></code></a></li>
<li><a class="reference internal" href="#speakerbox.preprocess.expand_gecko_annotations_to_dataset"><code class="docutils literal notranslate"><span class="pre">expand_gecko_annotations_to_dataset()</span></code></a></li>
<li><a class="reference internal" href="#speakerbox.preprocess.expand_labeled_diarized_audio_dir_to_dataset"><code class="docutils literal notranslate"><span class="pre">expand_labeled_diarized_audio_dir_to_dataset()</span></code></a></li>
<li><a class="reference internal" href="#speakerbox.preprocess.prepare_dataset"><code class="docutils literal notranslate"><span class="pre">prepare_dataset()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#module-speakerbox.types">speakerbox.types module</a><ul>
<li><a class="reference internal" href="#speakerbox.types.AnnotatedAudio"><code class="docutils literal notranslate"><span class="pre">AnnotatedAudio</span></code></a><ul>
<li><a class="reference internal" href="#speakerbox.types.AnnotatedAudio.audio"><code class="docutils literal notranslate"><span class="pre">AnnotatedAudio.audio</span></code></a></li>
<li><a class="reference internal" href="#speakerbox.types.AnnotatedAudio.conversation_id"><code class="docutils literal notranslate"><span class="pre">AnnotatedAudio.conversation_id</span></code></a></li>
<li><a class="reference internal" href="#speakerbox.types.AnnotatedAudio.duration"><code class="docutils literal notranslate"><span class="pre">AnnotatedAudio.duration</span></code></a></li>
<li><a class="reference internal" href="#speakerbox.types.AnnotatedAudio.from_dict"><code class="docutils literal notranslate"><span class="pre">AnnotatedAudio.from_dict()</span></code></a></li>
<li><a class="reference internal" href="#speakerbox.types.AnnotatedAudio.from_json"><code class="docutils literal notranslate"><span class="pre">AnnotatedAudio.from_json()</span></code></a></li>
<li><a class="reference internal" href="#speakerbox.types.AnnotatedAudio.label"><code class="docutils literal notranslate"><span class="pre">AnnotatedAudio.label</span></code></a></li>
<li><a class="reference internal" href="#speakerbox.types.AnnotatedAudio.schema"><code class="docutils literal notranslate"><span class="pre">AnnotatedAudio.schema()</span></code></a></li>
<li><a class="reference internal" href="#speakerbox.types.AnnotatedAudio.to_dict"><code class="docutils literal notranslate"><span class="pre">AnnotatedAudio.to_dict()</span></code></a></li>
<li><a class="reference internal" href="#speakerbox.types.AnnotatedAudio.to_json"><code class="docutils literal notranslate"><span class="pre">AnnotatedAudio.to_json()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#speakerbox.types.GeckoAnnotationAndAudio"><code class="docutils literal notranslate"><span class="pre">GeckoAnnotationAndAudio</span></code></a><ul>
<li><a class="reference internal" href="#speakerbox.types.GeckoAnnotationAndAudio.annotation_file"><code class="docutils literal notranslate"><span class="pre">GeckoAnnotationAndAudio.annotation_file</span></code></a></li>
<li><a class="reference internal" href="#speakerbox.types.GeckoAnnotationAndAudio.audio_file"><code class="docutils literal notranslate"><span class="pre">GeckoAnnotationAndAudio.audio_file</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#module-speakerbox.utils">speakerbox.utils module</a><ul>
<li><a class="reference internal" href="#speakerbox.utils.set_global_seed"><code class="docutils literal notranslate"><span class="pre">set_global_seed()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#module-speakerbox">Module contents</a><ul>
<li><a class="reference internal" href="#speakerbox.apply"><code class="docutils literal notranslate"><span class="pre">apply()</span></code></a></li>
<li><a class="reference internal" href="#speakerbox.eval_model"><code class="docutils literal notranslate"><span class="pre">eval_model()</span></code></a></li>
<li><a class="reference internal" href="#speakerbox.train"><code class="docutils literal notranslate"><span class="pre">train()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/sphinx_highlight.js"></script>
    <script src="_static/scripts/furo.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    </body>
</html>